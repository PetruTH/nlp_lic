{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inttstbrd/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-uncased-v1\", do_lower_case=True)\n",
    "model = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-uncased-v1\")\n",
    "\n",
    "\n",
    "def get_embeddings(text):\n",
    "        tokenized_text = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_text)\n",
    "\n",
    "        word_embeddings = outputs.last_hidden_state\n",
    "        averaged_embedding = torch.mean(word_embeddings, dim=0)\n",
    "\n",
    "        return averaged_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_dict = {}\n",
    "\n",
    "def json_creator_context(cursor):\n",
    "    cursor.execute(\"select treeId, internalRep from Meaning\")\n",
    "    i = 0\n",
    "    for row in cursor:\n",
    "        i+=1\n",
    "        # print(i, \" / 384863\")\n",
    "        if i > 4:\n",
    "            break\n",
    "        \n",
    "        # for storing embedings use numpy.array(get_embeddings(row[1])) with , cls=NumpyArrayEncoder at json.dump\n",
    "        if row[0] not in json_dict.keys():\n",
    "            json_dict[row[0]] = [row[1]]\n",
    "        else:\n",
    "            json_dict[row[0]].append(row[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Date salvate cu succes în data.feather\n"
     ]
    }
   ],
   "source": [
    "import feather\n",
    "import pyarrow as pa\n",
    "\n",
    "def stocare_eficienta(data_dict, filename=\"data.feather\"):\n",
    "    \"\"\"\n",
    "    Stochează datele în format Feather.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        comprimat_dict = {}\n",
    "        for cheie, matrice_list in data_dict.items():\n",
    "            comprimat_dict[cheie] = [comprima_matrice(matrice) for matrice in matrice_list]\n",
    "        \n",
    "        print(comprimat_dict)\n",
    "        # schema = pa.Schema([\n",
    "        #     pa.field()\n",
    "        # ])\n",
    "        # table = pa.Table.from_pydict(data_dict, schema=schema)\n",
    "\n",
    "        # feather.write_dataframe(table, filename)\n",
    "        print(f\"Date salvate cu succes în {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Eroare la stocarea datelor: {e}\")\n",
    "\n",
    "def comprima_matrice(matrice):\n",
    "    \"\"\"\n",
    "    Compresează o matrice NumPy folosind zstandard.\n",
    "    \"\"\"\n",
    "    import zstandard as zstd\n",
    "    return zstd.compress(matrice.tobytes())\n",
    "\n",
    "def incarcare_eficienta(filename=\"data.feather\"):\n",
    "    \"\"\"\n",
    "    Încarcă datele din format Feather.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        comprimat_dict = feather.read_dataframe(filename)\n",
    "        decomprimat_dict = {}\n",
    "        for cheie, matrice_comprimate in comprimat_dict.items():\n",
    "            decomprimat_dict[cheie] = [decomprima_matrice(matrice) for matrice in matrice_comprimate]\n",
    "        return decomprimat_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Eroare la încărcarea datelor: {e}\")\n",
    "        return None\n",
    "\n",
    "def decomprima_matrice(comprimat):\n",
    "    \"\"\"\n",
    "    Decomprimă o matrice NumPy comprimată cu zstandard.\n",
    "    \"\"\"\n",
    "    import zstandard as zstd\n",
    "    return numpy.frombuffer(zstd.decompress(comprimat), dtype=numpy.float32)\n",
    "\n",
    "stocare_eficienta(json_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
