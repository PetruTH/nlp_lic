{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dexflex.prototype import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"ro_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All inflected forms extraction\n",
    "\n",
    "In the cell below I will present the method that will extract all the inflected words for a certain word from **dexonline DB**.\n",
    "\n",
    "\n",
    "The method is named **get_all_forms** and takes a spacy.Token object as a parameter and looks up in the JSONS generated from DB trying to find all the forms available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aif = [\n",
    "    (\"A ieșit la iveală adevărata fire a mamei vitrege.\", 1),\n",
    "    (\"Rece, crudă, geloasă pe frumusețea și șarmul Cenușăresei,\", 2),\n",
    "    (\"Ea era hotărâtă să susțină interesele propriilor sale fiice.\", 0),\n",
    "    (\"Castelul a ajuns o ruină.\", 0),\n",
    "]\n",
    "\n",
    "for sample in data_aif:\n",
    "    doc = nlp(sample[0])\n",
    "    all_forms_for_word = get_all_forms(doc[sample[1]])\n",
    "\n",
    "    print(f\"For target-word: {doc[sample[1]]} there are all the inflected forms\")\n",
    "    for form in all_forms_for_word:\n",
    "        print(form)\n",
    "    print(\"\\n\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oltenizare feature\n",
    "\n",
    "In the cell below I will present the first main feature of the **dexflex**.\n",
    "\n",
    "The method is named **oltenizare** and will change all the verbs found at a past perfect tense to past simple in a context.\n",
    "\n",
    "This method is added as an extension to the spacy package and can be called using **token._.oltenizare()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell there are multiple edge cases\n",
    "\n",
    "data_olt = [\n",
    "    \"sunt surprinsă că te-ai întors după mine.\",\n",
    "    \"dacă tu socoteşti că a fi încătuşat, jefuit este o nedreptate, atunci fugi\",\n",
    "    \"nu-şi mai făcea griji că va fi ucis.\",\n",
    "    \"succesul tău a fost puţin şi succesul meu.\",\n",
    "    \"Eu am plecat\",\n",
    "    \"El ar fi venit, dar nu\",\n",
    "    \"nu l-am mai văzut pe aici.\",\n",
    "    \"cenușăreasa va fi surprinsă.\",\n",
    "    \"nu a mai rămas nimic în ce să crezi.\",\n",
    "    \"atunci, prin ordin regal, acea fată va fi soția prințului.\",\n",
    "    \"El va pleca, dar ieri ar fi stat apoi a plecat.\",\n",
    "    \"vor deveni realitate.\",\n",
    "    \"Tu ai spus doar adevarul\",\n",
    "    \"o voi citi eu!\",\n",
    "    \"dar a fost așa de frumos!\",\n",
    "    \"vom mai vedea\",\n",
    "    \"a fost a mamei\",\n",
    "    \"ar fi bine să te descotorosești de aceste vise.\",\n",
    "    \"Nu mă îndoiesc că ați avut în minte întreaga scenă.\",\n",
    "    \"cred că am uitat de toate!\",\n",
    "    \"tot va fi interesat de una din ele, nu-i așa?\", \n",
    "    \"am să stau tot după tine.\",\n",
    "    \"nu-ţi fă griji pentru mine, e ziua ta cea mare.\",\n",
    "    \"Nu ai plecat atunci.\"\n",
    "    \n",
    "]\n",
    "\n",
    "for sample in data_olt:\n",
    "    doc = nlp(sample)\n",
    "    oltenized_doc = doc._.oltenizare()\n",
    "    print(f\"Original phrase: {doc}    VERSUS    'Oltenized' phrase: {oltenized_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell there are happy paths.\n",
    "\n",
    "data_olt_happy = [\n",
    "    \"Am terminat proiectul la timp.\",\n",
    "    \"Ea a învățat să cânte la pian.\",\n",
    "    \"Noi am fost la concert aseară.\",\n",
    "    \"El a cumpărat un nou telefon.\",\n",
    "    \"Am întâlnit un vechi prieten în parc.\",\n",
    "    \"Ei au reparat mașina stricată.\",\n",
    "    \"Tu ai scris o poezie frumoasă.\",\n",
    "    \"Am gătit o cină delicioasă.\",\n",
    "    \"Ea a făcut curățenie în casă.\",\n",
    "    \"Noi am jucat fotbal în weekend.\",\n",
    "    \"Ați fost la cinema ieri?\",\n",
    "    \"Am vizitat muzeul de artă.\",\n",
    "    \"El a uitat să aducă documentele.\",\n",
    "    \"Ea a primit un cadou de ziua ei.\",\n",
    "    \"Am văzut un spectacol de teatru.\",\n",
    "    \"Tu ai vorbit cu profesorul?\",\n",
    "    \"Ei au construit un parc nou.\",\n",
    "    \"Am citit un articol interesant.\",\n",
    "    \"El a desenat un portret frumos.\",\n",
    "    \"Noi am plantat flori în grădină.\"\n",
    "]\n",
    "\n",
    "for sample in data_olt_happy:\n",
    "    doc = nlp(sample)\n",
    "    oltenized_doc = doc._.oltenizare()\n",
    "    print(f\"Original phrase: {doc}    VERSUS    'Oltenized' phrase: {oltenized_doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms suggestion feature\n",
    "\n",
    "In the cell below I will present the second main feature of the **dexflex**.\n",
    "\n",
    "The method will be used for to suggest synonyms using dexonline database. This can be a really good language simplifaction pipeline and the most important thing is that the synonyms suggested are on the right inflection form for context.\n",
    "\n",
    "This method is added as an extension to the spacy package and can be called using **token._.get_syns()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this I will use the data from oltenizare feature - happy path\n",
    "\n",
    "\n",
    "data_olt_happy = [\n",
    "    (\"Am observat eroarea la timp.\", 2),\n",
    "    (\"Ea a învățat să cânte la pian.\", 4),\n",
    "    (\"Am observat eroarea la timp.\", 1),\n",
    "    (\"Ei au reparat mașina stricată.\", -2),\n",
    "    (\"Tu ai scris o poezie frumoasă.\", -2),\n",
    "    (\"Ea s-a gătit pentru o cină delicioasă.\", 3),\n",
    "    (\"El a uitat să aducă documentele.\", -2),\n",
    "    (\"Ea a primit un cadou de ziua ei.\", 4),\n",
    "    (\"Tu ai vorbit cu profesorul?\", -2),\n",
    "    (\"Ei au construit un parc nou.\", 2),\n",
    "    (\"El a plecat la camera lui.\", -3)\n",
    "]\n",
    "\n",
    "for sample in data_olt_happy:\n",
    "    doc = nlp(sample[0])\n",
    "    \n",
    "    syn_list = [syn[0] for syn in doc[sample[1]]._.get_syns()]\n",
    "    print(f\"Sinonimele sugerate pentru cuvantul: {doc[sample[1]]} sunt {syn_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp( \"Eu și el am fi plecat mai repede.\")\n",
    "from dexflex.data_worker import *\n",
    "\n",
    "print(force_plural_noun(doc[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
